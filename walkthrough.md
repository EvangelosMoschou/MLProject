# Walkthrough: Πρωτόκολλο Sigma-Omega

Το πρωτόκολλο "Sigma-Omega" αποτελεί την τελική εξέλιξη του συστήματος ταξινόμησης, συνδυάζοντας προηγμένες τεχνικές επεξεργασίας δεδομένων με στοχαστικές μεθόδους βελτιστοποίησης.

## Βασικές Καινοτομίες

### 1. Επεξεργασία Δεδομένων: Transductive Learning & Topology MixUp
Υλοποιήθηκε ένας **Transductive DAE** που αντιμετωπίζει τα σύνολα εκπαίδευσης και δοκιμής ως ενιαία πολλαπλότητα.
- **Topology MixUp**: Σε αντίθεση με το κλασικό MixUp, η ανάμειξη δειγμάτων γίνεται μόνο μεταξύ τοπολογικά γειτονικών σημείων, διατηρώντας τη δομή της πολλαπλότητας.
- **Αυτόματη Επιλογή Χαρακτηριστικών**: Αφαίρεση του 20% των χαρακτηριστικών με τη χαμηλότερη σημαντικότητα, μειώνοντας τον θόρυβο.

### 2. Στοχαστικά Μοντέλα
- **XGBoost DART**: Κατά την προσθήκη νέου δέντρου, ορισμένα υπάρχοντα δέντρα απενεργοποιούνται τυχαία (Dropout), αποτρέποντας την υπερβολική εξάρτηση από συγκεκριμένους μαθητές.
- **CatBoost Langevin**: Προσθήκη στοχαστικού θορύβου στις ενημερώσεις gradients, επιτρέποντας την αποφυγή στενών τοπικών ελαχίστων υπέρ ευρύτερων περιοχών γενίκευσης.

### 3. Τεχνικές Βελτιστοποίησης
- **Monte Carlo Ensemble**: Εκτέλεση του πρωτοκόλλου 5 φορές με διαφορετικά seeds (`42-46`) και υπολογισμός μέσου όρου, μειώνοντας τη διακύμανση.
- **Isotonic Calibration**: Χρήση μη-παραμετρικής απεικόνισης (Isotonic Regression) για ευθυγράμμιση των προβλεπόμενων πιθανοτήτων με τα πραγματικά ποσοστά σφάλματος.

## Αρχιτεκτονική Συστήματος
Το `solution_quantum.py` ενσωματώνει:
1.  **TabR**: Μοντέλο ανάκτησης με attention σε επεξεργασμένα δεδομένα.
2.  **ThetaTabM**: Gated MLP με SAM και MixUp (Βελτιστοποίηση RTX 3060: Batch 2048, LR 2e-3).
3.  **XGBoost DART**: Boosting με dropout σε χαρακτηριστικά πολλαπλότητας.
4.  **CatBoost Langevin**: Στοχαστικό boosting σε χαρακτηριστικά πολλαπλότητας.

## Execution
Run the Epsilon Protocol:
```bash
python3 PartD/solution_quantum.py
```
