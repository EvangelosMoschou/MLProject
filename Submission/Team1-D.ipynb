{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "fbfdd82f",
            "metadata": {},
            "source": [
                "# Machine Learning Project - Part D\n",
                "**Team 1**\n",
                "* Name: Evangelos Moschou\n",
                "* AEM: 10986\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "dde9a654",
            "metadata": {},
            "source": [
                "## Part D: Classification Challenge (Omega Protocol Build)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "78474ab6",
            "metadata": {},
            "source": [
                "import os\n",
                "import sys\n",
                "import copy\n",
                "import time\n",
                "import warnings\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import DataLoader, TensorDataset\n",
                "from sklearn.base import BaseEstimator, ClassifierMixin\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
                "from sklearn.preprocessing import QuantileTransformer, LabelEncoder, StandardScaler\n",
                "from sklearn.neighbors import NearestNeighbors, kneighbors_graph\n",
                "from sklearn.metrics import accuracy_score, roc_auc_score\n",
                "from catboost import CatBoostClassifier\n",
                "\n",
                "# ------------------------------------------------------------------------------\n",
                "# CONFIGURATION\n",
                "# ------------------------------------------------------------------------------\n",
                "warnings.filterwarnings('ignore')\n",
                "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "SEED = 42\n",
                "\n",
                "def seed_everything(seed=42):\n",
                "    import random\n",
                "    random.seed(seed)\n",
                "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
                "    np.random.seed(seed)\n",
                "    torch.manual_seed(seed)\n",
                "    if torch.cuda.is_available():\n",
                "        torch.cuda.manual_seed(seed)\n",
                "        torch.backends.cudnn.deterministic = True\n",
                "\n",
                "seed_everything(SEED)\n",
                "print(f\"[INIT] Device: {DEVICE}\")\n",
                "print(\"[INIT] Initializing Omega Protocol (Submission Build)...\")\n",
                "\n",
                "# --- Data Paths (Adjustment for notebook location) ---\n",
                "DATA_PATH_TRAIN = '../Datasets/datasetTV.csv'\n",
                "DATA_PATH_TEST = '../Datasets/datasetTest.csv'\n",
                "OUTPUT_FILE = 'labels1.npy'\n",
                "\n",
                "def load_data():\n",
                "    if not os.path.exists(DATA_PATH_TRAIN):\n",
                "        train_path = 'Datasets/datasetTV.csv'\n",
                "        test_path = 'Datasets/datasetTest.csv'\n",
                "    else:\n",
                "        train_path = DATA_PATH_TRAIN\n",
                "        test_path = DATA_PATH_TEST\n",
                "        \n",
                "    train_df = pd.read_csv(train_path, header=None)\n",
                "    test_df = pd.read_csv(test_path, header=None)\n",
                "    X = train_df.iloc[:, :-1].values\n",
                "    y = train_df.iloc[:, -1].values\n",
                "    X_test = test_df.values\n",
                "    return X, y, X_test\n",
                "\n",
                "# ------------------------------------------------------------------------------\n",
                "# 1. TABULAR DAE (THE TURBOCHARGER)\n",
                "# ------------------------------------------------------------------------------\n",
                "class TabularDAE(nn.Module):\n",
                "    def __init__(self, input_dim, hidden_dim=256, bottleneck_dim=64, noise_factor=0.1):\n",
                "        super(TabularDAE, self).__init__()\n",
                "        self.noise_factor = noise_factor\n",
                "        self.encoder = nn.Sequential(\n",
                "            nn.Linear(input_dim, hidden_dim), nn.BatchNorm1d(hidden_dim), nn.SiLU(),\n",
                "            nn.Linear(hidden_dim, bottleneck_dim), nn.BatchNorm1d(bottleneck_dim), nn.SiLU() \n",
                "        )\n",
                "        self.decoder = nn.Sequential(\n",
                "            nn.Linear(bottleneck_dim, hidden_dim), nn.BatchNorm1d(hidden_dim), nn.SiLU(),\n",
                "            nn.Linear(hidden_dim, input_dim)\n",
                "        )\n",
                "    def forward(self, x): return self.decoder(self.encoder(x))\n",
                "    def get_embedding(self, x):\n",
                "        with torch.no_grad(): return self.encoder(x)\n",
                "\n",
                "class DAE_Embedder:\n",
                "    def __init__(self, input_dim, device=DEVICE):\n",
                "        self.device = device\n",
                "        self.model = TabularDAE(input_dim).to(device)\n",
                "    def fit(self, X_all, epochs=30, batch_size=256):\n",
                "        print(f\"\\n[DAE] Training Turbocharger on {X_all.shape} samples...\")\n",
                "        optimizer = optim.AdamW(self.model.parameters(), lr=1e-3)\n",
                "        criterion = nn.MSELoss()\n",
                "        X_t = torch.tensor(X_all, dtype=torch.float32).to(self.device)\n",
                "        loader = DataLoader(TensorDataset(X_t), batch_size=batch_size, shuffle=True)\n",
                "        self.model.train()\n",
                "        for ep in range(epochs):\n",
                "            for batch in loader:\n",
                "                x_clean = batch[0]\n",
                "                noise = torch.randn_like(x_clean) * self.model.noise_factor\n",
                "                optimizer.zero_grad()\n",
                "                recon = self.model(x_clean + noise)\n",
                "                loss = criterion(recon, x_clean)\n",
                "                loss.backward()\n",
                "                optimizer.step()\n",
                "        return self\n",
                "    def transform(self, X):\n",
                "        self.model.eval()\n",
                "        with torch.no_grad(): return self.model.get_embedding(torch.tensor(X, dtype=torch.float32).to(self.device)).cpu().numpy()\n",
                "\n",
                "# ------------------------------------------------------------------------------\n",
                "# 2. WEIGHTED MANIFOLD TTA\n",
                "# ------------------------------------------------------------------------------\n",
                "def predict_proba_tta(model, X, knn_indices, knn_dists, alpha=0.3):\n",
                "    p_base = model.predict_proba(X)\n",
                "    sigma = 1.0\n",
                "    weights = np.exp(- (knn_dists ** 2) / (2 * sigma ** 2))\n",
                "    weights = weights / (weights.sum(axis=1, keepdims=True) + 1e-10)\n",
                "    N, k = knn_indices.shape; C = p_base.shape[1]\n",
                "    flat_probs = p_base[knn_indices.flatten()].reshape(N, k, C)\n",
                "    p_smooth = (flat_probs * weights[:, :, np.newaxis]).sum(axis=1)\n",
                "    return (1 - alpha) * p_base + alpha * p_smooth\n",
                "\n",
                "# ------------------------------------------------------------------------------\n",
                "# 3. STRATEGIC CLASSES\n",
                "# ------------------------------------------------------------------------------\n",
                "class AdversarialWeigher:\n",
                "    def fit_transform(self, X_train, X_test):\n",
                "        X_drift = np.vstack([X_train, X_test])\n",
                "        y_drift = np.hstack([np.zeros(len(X_train)), np.ones(len(X_test))])\n",
                "        clf = RandomForestClassifier(n_estimators=50, max_depth=6, random_state=SEED, n_jobs=-1)\n",
                "        probs = cross_val_predict(clf, X_drift, y_drift, cv=5, method='predict_proba')[:, 1]\n",
                "        train_probs = probs[:len(X_train)]\n",
                "        weights = np.clip(train_probs / (1 - train_probs + 1e-6), 0.1, 10.0)\n",
                "        return weights / weights.mean()\n",
                "\n",
                "class ManifoldEngineer:\n",
                "    def transform(self, X_train, X_test):\n",
                "        X_all = np.vstack([X_train, X_test])\n",
                "        knn = NearestNeighbors(n_neighbors=20, n_jobs=-1).fit(X_all)\n",
                "        dists, indices = knn.kneighbors(X_all)\n",
                "        k=20; d_k = dists[:, -1].reshape(-1, 1); d_j = dists[:, 1:]\n",
                "        lid = k / np.sum(np.log(d_k / (d_j + 1e-10) + 1e-10), axis=1)\n",
                "        scaler = StandardScaler(); feats = scaler.fit_transform(lid.reshape(-1, 1))\n",
                "        X_tr_n = np.hstack([X_train, feats[:len(X_train)]])\n",
                "        X_te_n = np.hstack([X_test, feats[len(X_train):]])\n",
                "        knn_test = NearestNeighbors(n_neighbors=6, n_jobs=-1).fit(X_test)\n",
                "        d_test, i_test = knn_test.kneighbors(X_test)\n",
                "        return X_tr_n, X_te_n, i_test, d_test\n",
                "\n",
                "# ------------------------------------------------------------------------------\n",
                "# 4. ARCHITECTURES\n",
                "# ------------------------------------------------------------------------------\n",
                "class NeuralProxyClassifier(BaseEstimator, ClassifierMixin):\n",
                "    def __init__(self, input_dim, num_classes, type='TabM'):\n",
                "        self.input_dim = input_dim; self.num_classes = num_classes; self.type = type\n",
                "    def fit(self, X, y, w=None):\n",
                "        self.model = nn.Sequential(\n",
                "            nn.Linear(self.input_dim, 256), nn.LayerNorm(256), nn.SiLU(), nn.Dropout(0.1),\n",
                "            nn.Linear(256, 128), nn.LayerNorm(128), nn.SiLU(),\n",
                "            nn.Linear(128, self.num_classes)\n",
                "        ).to(DEVICE)\n",
                "        opt = optim.AdamW(self.model.parameters(), lr=1e-3); crit = nn.CrossEntropyLoss(reduction='none')\n",
                "        Xt = torch.tensor(X, dtype=torch.float32).to(DEVICE); yt = torch.tensor(y, dtype=torch.long).to(DEVICE)\n",
                "        wt = torch.tensor(w, dtype=torch.float32).to(DEVICE) if w is not None else torch.ones(len(X)).to(DEVICE)\n",
                "        dl = DataLoader(TensorDataset(Xt, yt, wt), batch_size=256, shuffle=True)\n",
                "        self.model.train()\n",
                "        for _ in range(30):\n",
                "            for xb, yb, wb in dl:\n",
                "                opt.zero_grad(); (crit(self.model(xb), yb) * wb).mean().backward(); opt.step()\n",
                "        return self\n",
                "    def predict_proba(self, X):\n",
                "        self.model.eval()\n",
                "        with torch.no_grad(): return torch.softmax(self.model(torch.tensor(X, dtype=torch.float32).to(DEVICE)), dim=1).cpu().numpy()\n",
                "\n",
                "# ------------------------------------------------------------------------------\n",
                "# 5. MAIN OMEGA LOOP\n",
                "# ------------------------------------------------------------------------------\n",
                "def main():\n",
                "    print(\"--- Part D: The Omega Protocol Build ---\")\n",
                "    X, y, X_test = load_data()\n",
                "    le = LabelEncoder(); y_enc = le.fit_transform(y)\n",
                "    \n",
                "    # Preprocessing\n",
                "    qt = QuantileTransformer(output_distribution='normal', random_state=SEED)\n",
                "    X_gauss = qt.fit_transform(X); X_test_gauss = qt.transform(X_test)\n",
                "    \n",
                "    eng = ManifoldEngineer()\n",
                "    X_topo, X_test_topo, tta_idxs, tta_dists = eng.transform(X, X_test)\n",
                "    \n",
                "    weigher = AdversarialWeigher(); weights = weigher.fit_transform(X, X_test)\n",
                "    \n",
                "    # DAE Pre-training\n",
                "    dae = DAE_Embedder(X_gauss.shape[1]).fit(np.vstack([X_gauss, X_test_gauss]))\n",
                "    X_nn_tr = np.hstack([X_gauss, dae.transform(X_gauss)])\n",
                "    X_nn_te = np.hstack([X_test_gauss, dae.transform(X_test_gauss)])\n",
                "    \n",
                "    # Models\n",
                "    models = {\n",
                "        'TabM_Proxy': NeuralProxyClassifier(X_nn_tr.shape[1], len(le.classes_)),\n",
                "        'TurboTabR_Base': CatBoostClassifier(iterations=1000, depth=8, learning_rate=0.03, verbose=False, allow_writing_files=False, task_type='GPU' if torch.cuda.is_available() else 'CPU')\n",
                "    }\n",
                "    \n",
                "    test_preds = {}\n",
                "    for name, model in models.items():\n",
                "        print(f\"Training {name}...\")\n",
                "        if 'Proxy' in name: \n",
                "            model.fit(X_nn_tr, y_enc, w=weights)\n",
                "            test_preds[name] = predict_proba_tta(model, X_nn_te, tta_idxs, tta_dists)\n",
                "        else: \n",
                "            model.fit(X_topo, y_enc, sample_weight=weights)\n",
                "            test_preds[name] = predict_proba_tta(model, X_test_topo, tta_idxs, tta_dists)\n",
                "            \n",
                "    # Diamond Consensus\n",
                "    print(\"Mining Diamonds...\")\n",
                "    valid = list(test_preds.keys()); diamond_idx = []\n",
                "    for i in range(len(X_test)):\n",
                "        votes = [np.argmax(test_preds[v][i]) for v in valid]\n",
                "        confs = [np.max(test_preds[v][i]) for v in valid]\n",
                "        if len(set(votes)) == 1 and min(confs) > 0.95: diamond_idx.append(i)\n",
                "        \n",
                "    print(f\"Found {len(diamond_idx)} Diamonds.\")\n",
                "    \n",
                "    # Final Refit or Average\n",
                "    if len(diamond_idx) > 20:\n",
                "        X_pseudo = X_topo[diamond_idx]; y_pseudo = [np.argmax(test_preds[valid[0]][i]) for i in diamond_idx]\n",
                "        anchor = CatBoostClassifier(iterations=1000, verbose=False, allow_writing_files=False, task_type='GPU' if torch.cuda.is_available() else 'CPU')\n",
                "        anchor.fit(np.vstack([X_topo, X_pseudo]), np.hstack([y_enc, y_pseudo]), sample_weight=np.hstack([weights, np.ones(len(y_pseudo))*1.5]))\n",
                "        final_probs = predict_proba_tta(anchor, X_test_topo, tta_idxs, tta_dists)\n",
                "    else:\n",
                "        final_probs = np.mean([test_preds[v] for v in valid], axis=0)\n",
                "        \n",
                "    final_labels = le.inverse_transform(np.argmax(final_probs, axis=1))\n",
                "    np.save(OUTPUT_FILE, final_labels.astype(int))\n",
                "    print(f\"\\nâœ… Process Complete. Results saved to {OUTPUT_FILE}\")\n",
                "    \n",
                "if __name__ == '__main__':\n",
                "    main()\n"
            ]
        }
    ],
    "metadata": {},
    "nbformat": 4,
    "nbformat_minor": 5
}